### YamlMime:TSType
name: DataLakeFileSystemClient
uid: '@azure/storage-file-datalake.DataLakeFileSystemClient|beta'
package: '@azure/storage-file-datalake|beta'
summary: |-
  A DataLakeFileSystemClient represents a URL to the Azure Storage file system
  allowing you to manipulate its directories and files.
fullName: DataLakeFileSystemClient
remarks: ''
isPreview: false
isDeprecated: false
type: class
constructors:
  - name: DataLakeFileSystemClient(string, Pipeline)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.constructor_1|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: Creates an instance of DataLakeFileSystemClient from url and pipeline.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'new DataLakeFileSystemClient(url: string, pipeline: Pipeline)'
      parameters:
        - id: url
          type: string
          description: >-
            A Client string pointing to Azure Storage data lake file system,
            such as
                                "https://myaccount.dfs.core.windows.net/filesystem". You can append a SAS
                                if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem?sasString".
        - id: pipeline
          type: <xref uid="@azure/storage-file-datalake.Pipeline|beta" />
          description: |
            Call newPipeline() to create a default
                                       pipeline, or provide a customized pipeline.
  - name: >-
      DataLakeFileSystemClient(string, StorageSharedKeyCredential |
      AnonymousCredential | TokenCredential, StoragePipelineOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.constructor|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: Creates an instance of DataLakeFileSystemClient from url and credential.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        new DataLakeFileSystemClient(url: string, credential?:
        StorageSharedKeyCredential | AnonymousCredential | TokenCredential,
        options?: StoragePipelineOptions)
      parameters:
        - id: url
          type: string
          description: >-
            A Client string pointing to Azure Storage data lake file system,
            such as
                                "https://myaccount.dfs.core.windows.net/filesystem". You can append a SAS
                                if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem?sasString".
        - id: credential
          type: >-
            <xref
            uid="@azure/storage-file-datalake.StorageSharedKeyCredential|beta"
            /> | <xref
            uid="@azure/storage-file-datalake.AnonymousCredential|beta" /> |
            TokenCredential
          description: >-
            Such as AnonymousCredential, StorageSharedKeyCredential or any
            credential from the `@azure/identity` package to authenticate
            requests to the service. You can also provide an object that
            implements the TokenCredential interface. If not specified,
            AnonymousCredential is used.
        - id: options
          type: >-
            <xref uid="@azure/storage-file-datalake.StoragePipelineOptions|beta"
            />
          description: |
            Optional. Options to configure the HTTP pipeline.
properties:
  - name: accountName
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.accountName|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: ''
    fullName: accountName
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'accountName: string'
      return:
        description: ''
        type: string
  - name: credential
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.credential|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Such as AnonymousCredential, StorageSharedKeyCredential or any credential
      from the `@azure/identity` package to authenticate requests to the
      service. You can also provide an object that implements the
      TokenCredential interface. If not specified, AnonymousCredential is used.
    fullName: credential
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        credential: StorageSharedKeyCredential | AnonymousCredential |
        TokenCredential
      return:
        description: ''
        type: >-
          <xref
          uid="@azure/storage-file-datalake.StorageSharedKeyCredential|beta" />
          | <xref uid="@azure/storage-file-datalake.AnonymousCredential|beta" />
          | TokenCredential
  - name: name
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.name|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: Name of current file system.
    fullName: name
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: string name
      return:
        description: ''
        type: string
  - name: url
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.url|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: Encoded URL string value.
    fullName: url
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'url: string'
      return:
        description: ''
        type: string
methods:
  - name: create(FileSystemCreateOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.create|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Creates a new file system under the specified account. If the file system
      with

      the same name already exists, the operation fails.


      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function create(options?: FileSystemCreateOptions):
        Promise<FileSystemCreateResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemCreateOptions|beta" />
          description: |
            Optional. Options when creating file system.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemCreateResponse|beta"
          />&gt;
  - name: createIfNotExists(FileSystemCreateOptions)
    uid: >-
      @azure/storage-file-datalake.DataLakeFileSystemClient.createIfNotExists|beta
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Creates a new file system under the specified account. If the file system
      with

      the same name already exists, it is not changed.


      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function createIfNotExists(options?: FileSystemCreateOptions):
        Promise<FileSystemCreateIfNotExistsResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemCreateOptions|beta" />
          description: |
            -
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemCreateIfNotExistsResponse|beta"
          />&gt;
  - name: delete(FileSystemDeleteOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.delete|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Delete current file system.


      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function delete(options?: FileSystemDeleteOptions):
        Promise<FileSystemDeleteResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemDeleteOptions|beta" />
          description: |
            Optional. Options when deleting file system.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemDeleteResponse|beta"
          />&gt;
  - name: deleteIfExists(FileSystemDeleteOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.deleteIfExists|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Delete current file system if it exists.


      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function deleteIfExists(options?: FileSystemDeleteOptions):
        Promise<FileSystemDeleteIfExistsResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemDeleteOptions|beta" />
          description: |
            -
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemDeleteIfExistsResponse|beta"
          />&gt;
  - name: exists(FileSystemExistsOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.exists|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >
      Returns true if the File system represented by this client exists; false
      otherwise.

      NOTE: use this function with care since an existing file system might be
      deleted by other clients or

      applications. Vice versa new file system with the same name might be added
      by other clients or

      applications after this function completes.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'function exists(options?: FileSystemExistsOptions): Promise<boolean>'
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemExistsOptions|beta" />
          description: |
            -
      return:
        description: ''
        type: Promise&lt;boolean&gt;
  - name: generateSasUrl(FileSystemGenerateSasUrlOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.generateSasUrl|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Only available for DataLakeFileSystemClient constructed with a shared key
      credential.

      Generates a Service Shared Access Signature (SAS) URI based on the client
      properties

      and parameters passed in. The SAS is signed by the shared key credential
      of the client.



      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function generateSasUrl(options: FileSystemGenerateSasUrlOptions):
        Promise<string>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemGenerateSasUrlOptions|beta"
            />
          description: Optional parameters.
      return:
        description: >-
          The SAS URI consisting of the URI to the resource represented by this
          client, followed by the generated SAS token.
        type: Promise&lt;string&gt;
  - name: getAccessPolicy(FileSystemGetAccessPolicyOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.getAccessPolicy|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Gets the permissions for the specified file system. The permissions
      indicate

      whether file system data may be accessed publicly.

      WARNING: JavaScript Date will potentially lose precision when parsing
      startsOn and expiresOn strings.

      For example, new Date("2018-12-31T03:44:23.8827891Z").toISOString() will
      get "2018-12-31T03:44:23.882Z".



      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-acl
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function getAccessPolicy(options?: FileSystemGetAccessPolicyOptions):
        Promise<FileSystemGetAccessPolicyResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemGetAccessPolicyOptions|beta"
            />
          description: |
            Optional. Options when getting file system access policy.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemGetAccessPolicyResponse|beta"
          />&gt;
  - name: getDataLakeLeaseClient(string)
    uid: >-
      @azure/storage-file-datalake.DataLakeFileSystemClient.getDataLakeLeaseClient|beta
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Get a
      <xref:@azure/storage-file-datalake.DataLakeDirectoryClient.getDataLakeLeaseClient>
      that manages leases on the file system.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function getDataLakeLeaseClient(proposeLeaseId?: string):
        DataLakeLeaseClient
      parameters:
        - id: proposeLeaseId
          type: string
          description: |
            Optional. Initial proposed lease Id.
      return:
        description: ''
        type: <xref uid="@azure/storage-file-datalake.DataLakeLeaseClient|beta" />
  - name: getDirectoryClient(string)
    uid: >-
      @azure/storage-file-datalake.DataLakeFileSystemClient.getDirectoryClient|beta
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Creates a <xref:@azure/storage-file-datalake.DataLakeDirectoryClient>
      object under current file system.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function getDirectoryClient(directoryName: string):
        DataLakeDirectoryClient
      parameters:
        - id: directoryName
          type: string
          description: |
            -
      return:
        description: ''
        type: >-
          <xref uid="@azure/storage-file-datalake.DataLakeDirectoryClient|beta"
          />
  - name: getFileClient(string)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.getFileClient|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Creates a <xref:@azure/storage-file-datalake.DataLakeFileClient> object
      under current file system.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'function getFileClient(fileName: string): DataLakeFileClient'
      parameters:
        - id: fileName
          type: string
          description: |
            -
      return:
        description: ''
        type: <xref uid="@azure/storage-file-datalake.DataLakeFileClient|beta" />
  - name: getProperties(FileSystemGetPropertiesOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.getProperties|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Returns all user-defined metadata and system properties for the specified

      file system.

      WARNING: The `metadata` object returned in the response will have its keys
      in lowercase, even if

      they originally contained uppercase characters. This differs from the
      metadata keys returned by

      the `listFileSystems` method of
      <xref:@azure/storage-file-datalake.DataLakeServiceClient> using the
      `includeMetadata` option, which

      will retain their original casing.



      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-properties
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function getProperties(options?: FileSystemGetPropertiesOptions):
        Promise<FileSystemGetPropertiesResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemGetPropertiesOptions|beta"
            />
          description: |
            Optional. Options when getting file system properties.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemGetPropertiesResponse|beta"
          />&gt;
  - name: listDeletedPaths(ListDeletedPathsOptions)
    uid: >-
      @azure/storage-file-datalake.DataLakeFileSystemClient.listDeletedPaths|beta
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Returns an async iterable iterator to list all the paths (directories and
      files)

      under the specified file system.

      .byPage() returns an async iterable iterator to list the paths in pages.


      Example using `for await` syntax:


      ```js

      // Get the fileSystemClient before you run these snippets,

      // Can be obtained from
      `serviceClient.getFileSystemClient("<your-filesystem-name>");`

      let i = 1;

      for await (const deletePath of fileSystemClient.listDeletedPaths()) {
        console.log(`Path ${i++}: ${deletePath.name}`);
      }

      ```


      Example using `iter.next()`:


      ```js

      let i = 1;

      let iter = fileSystemClient.listDeletedPaths();

      let deletedPathItem = await iter.next();

      while (!deletedPathItem.done) {
        console.log(`Path ${i++}: ${deletedPathItem.value.name}`);
        pathItem = await iter.next();
      }

      ```


      Example using `byPage()`:


      ```js

      // passing optional maxPageSize in the page settings

      let i = 1;

      for await (const response of fileSystemClient.listDeletedPaths().byPage({
      maxPageSize: 20 })) {
        for (const deletePath of response.pathItems) {
          console.log(`Path ${i++}: ${deletePath.name}`);
        }
      }

      ```


      Example using paging with a marker:


      ```js

      let i = 1;

      let iterator = fileSystemClient.listDeletedPaths().byPage({ maxPageSize: 2
      });

      let response = (await iterator.next()).value;


      // Prints 2 path names

      for (const path of response.pathItems) {
        console.log(`Path ${i++}: ${path.name}}`);
      }


      // Gets next marker

      let marker = response.continuationToken;


      // Passing next marker as continuationToken


      iterator = fileSystemClient.listDeletedPaths().byPage({ continuationToken:
      marker, maxPageSize: 10 });

      response = (await iterator.next()).value;


      // Prints 10 path names

      for (const deletePath of response.deletedPathItems) {
        console.log(`Path ${i++}: ${deletePath.name}`);
      }

      ```



      See https://docs.microsoft.com/rest/api/storageservices/list-blobs
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function listDeletedPaths(options?: ListDeletedPathsOptions):
        PagedAsyncIterableIterator<DeletedPath,
        FileSystemListDeletedPathsResponse>
      parameters:
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.ListDeletedPathsOptions|beta" />
          description: |
            Optional. Options when listing deleted paths.
      return:
        description: ''
        type: >-
          PagedAsyncIterableIterator&lt;<xref
          uid="@azure/storage-file-datalake.DeletedPath|beta" />, <xref
          uid="@azure/storage-file-datalake.FileSystemListDeletedPathsResponse|beta"
          />&gt;
  - name: listPaths(ListPathsOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.listPaths|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Returns an async iterable iterator to list all the paths (directories and
      files)

      under the specified file system.

      .byPage() returns an async iterable iterator to list the paths in pages.


      Example using `for await` syntax:


      ```js

      // Get the fileSystemClient before you run these snippets,

      // Can be obtained from
      `serviceClient.getFileSystemClient("<your-filesystem-name>");`

      let i = 1;

      for await (const path of fileSystemClient.listPaths()) {
        console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
      }

      ```


      Example using `iter.next()`:


      ```js

      let i = 1;

      let iter = fileSystemClient.listPaths();

      let pathItem = await iter.next();

      while (!pathItem.done) {
        console.log(`Path ${i++}: ${pathItem.value.name}, isDirectory?: ${pathItem.value.isDirectory}`);
        pathItem = await iter.next();
      }

      ```


      Example using `byPage()`:


      ```js

      // passing optional maxPageSize in the page settings

      let i = 1;

      for await (const response of fileSystemClient.listPaths().byPage({
      maxPageSize: 20 })) {
        for (const path of response.pathItems) {
          console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
        }
      }

      ```


      Example using paging with a marker:


      ```js

      let i = 1;

      let iterator = fileSystemClient.listPaths().byPage({ maxPageSize: 2 });

      let response = (await iterator.next()).value;


      // Prints 2 path names

      for (const path of response.pathItems) {
        console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
      }


      // Gets next marker

      let marker = response.continuationToken;


      // Passing next marker as continuationToken


      iterator = fileSystemClient.listPaths().byPage({ continuationToken:
      marker, maxPageSize: 10 });

      response = (await iterator.next()).value;


      // Prints 10 path names

      for (const path of response.pathItems) {
        console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
      }

      ```



      See https://docs.microsoft.com/rest/api/storageservices/list-blobs
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function listPaths(options?: ListPathsOptions):
        PagedAsyncIterableIterator<Path, FileSystemListPathsResponse>
      parameters:
        - id: options
          type: <xref uid="@azure/storage-file-datalake.ListPathsOptions|beta" />
          description: |
            Optional. Options when listing paths.
      return:
        description: ''
        type: >-
          PagedAsyncIterableIterator&lt;<xref
          uid="@azure/storage-file-datalake.Path|beta" />, <xref
          uid="@azure/storage-file-datalake.FileSystemListPathsResponse|beta"
          />&gt;
  - name: >-
      setAccessPolicy(PublicAccessType, SignedIdentifier<AccessPolicy>[],
      FileSystemSetAccessPolicyOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.setAccessPolicy|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Sets the permissions for the specified file system. The permissions
      indicate

      whether directories or files in a file system may be accessed publicly.

      When you set permissions for a file system, the existing permissions are
      replaced.

      If no access or containerAcl provided, the existing file system ACL will
      be

      removed.



      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-acl
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function setAccessPolicy(access?: PublicAccessType, fileSystemAcl?:
        SignedIdentifier<AccessPolicy>[], options?:
        FileSystemSetAccessPolicyOptions):
        Promise<FileSystemSetAccessPolicyResponse>
      parameters:
        - id: access
          type: <xref uid="@azure/storage-file-datalake.PublicAccessType|beta" />
          description: Optional. The level of public access to data in the file system.
        - id: fileSystemAcl
          type: >-
            <xref uid="@azure/storage-file-datalake.SignedIdentifier|beta"
            />&lt;<xref uid="@azure/storage-file-datalake.AccessPolicy|beta"
            />&gt;[]
          description: >-
            Optional. Array of elements each having a unique Id and details of
            the access policy.
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemSetAccessPolicyOptions|beta"
            />
          description: |
            Optional. Options when setting file system access policy.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemSetAccessPolicyResponse|beta"
          />&gt;
  - name: setMetadata(Metadata, FileSystemSetMetadataOptions)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.setMetadata|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Sets one or more user-defined name-value pairs for the specified file
      system.

      If no option provided, or no metadata defined in the parameter, the file
      system

      metadata will be removed.



      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-metadata
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function setMetadata(metadata?: Metadata, options?:
        FileSystemSetMetadataOptions): Promise<FileSystemSetMetadataResponse>
      parameters:
        - id: metadata
          type: <xref uid="@azure/storage-file-datalake.Metadata|beta" />
          description: |-
            Replace existing metadata with this value.
                                         If no value provided the existing metadata will be removed.
        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemSetMetadataOptions|beta"
            />
          description: |
            Optional. Options when setting file system metadata.
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemSetMetadataResponse|beta"
          />&gt;
  - name: undeletePath(string, string, FileSystemUndeletePathOption)
    uid: '@azure/storage-file-datalake.DataLakeFileSystemClient.undeletePath|beta'
    package: '@azure/storage-file-datalake|beta'
    summary: >-
      Restores a soft deleted path.


      See
      https://docs.microsoft.com/en-us/rest/api/storageservices/undelete-blob
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function undeletePath(deletedPath: string, deletionId: string, options?:
        FileSystemUndeletePathOption): Promise<FileSystemUndeletePathResponse>
      parameters:
        - id: deletedPath
          type: string
          description: |
            Required.  The path of the deleted path.
        - id: deletionId
          type: string
          description: |+
            Required.  The deletion ID associated with the soft deleted path.

        - id: options
          type: >-
            <xref
            uid="@azure/storage-file-datalake.FileSystemUndeletePathOption|beta"
            />
          description: ''
      return:
        description: ''
        type: >-
          Promise&lt;<xref
          uid="@azure/storage-file-datalake.FileSystemUndeletePathResponse|beta"
          />&gt;
extends: <xref uid="@azure/storage-file-datalake.StorageClient|beta" />
