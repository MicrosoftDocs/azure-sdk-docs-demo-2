### YamlMime:TSType
name: AnalyzeRequest
uid: '@azure/search-documents.AnalyzeRequest|beta'
package: '@azure/search-documents|beta'
summary: >-
  Specifies some text and analysis components used to break that text into
  tokens.
fullName: AnalyzeRequest
remarks: ''
isPreview: false
isDeprecated: false
type: interface
properties:
  - name: analyzerName
    uid: '@azure/search-documents.AnalyzeRequest.analyzerName|beta'
    package: '@azure/search-documents|beta'
    summary: >-
      The name of the analyzer to use to break the given text. If this parameter
      is not specified,

      you must specify a tokenizer instead. The tokenizer and analyzer
      parameters are mutually

      exclusive. KnownAnalyzerNames is an enum containing known values.

      NOTE: Either analyzerName or tokenizerName is required in an
      AnalyzeRequest.
    fullName: analyzerName
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'analyzerName?: string'
      return:
        description: ''
        type: string
  - name: charFilters
    uid: '@azure/search-documents.AnalyzeRequest.charFilters|beta'
    package: '@azure/search-documents|beta'
    summary: >-
      An optional list of character filters to use when breaking the given text.
      This parameter can

      only be set when using the tokenizer parameter.
    fullName: charFilters
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'charFilters?: string[]'
      return:
        description: ''
        type: string[]
  - name: normalizerName
    uid: '@azure/search-documents.AnalyzeRequest.normalizerName|beta'
    package: '@azure/search-documents|beta'
    summary: The name of the normalizer to use to normalize the given text.
    fullName: normalizerName
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'normalizerName?: LexicalNormalizerName'
      return:
        description: ''
        type: <xref uid="@azure/search-documents.LexicalNormalizerName|beta" />
  - name: text
    uid: '@azure/search-documents.AnalyzeRequest.text|beta'
    package: '@azure/search-documents|beta'
    summary: The text to break into tokens.
    fullName: text
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'text: string'
      return:
        description: ''
        type: string
  - name: tokenFilters
    uid: '@azure/search-documents.AnalyzeRequest.tokenFilters|beta'
    package: '@azure/search-documents|beta'
    summary: >-
      An optional list of token filters to use when breaking the given text.
      This parameter can only

      be set when using the tokenizer parameter.
    fullName: tokenFilters
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'tokenFilters?: string[]'
      return:
        description: ''
        type: string[]
  - name: tokenizerName
    uid: '@azure/search-documents.AnalyzeRequest.tokenizerName|beta'
    package: '@azure/search-documents|beta'
    summary: >-
      The name of the tokenizer to use to break the given text. If this
      parameter is not specified,

      you must specify an analyzer instead. The tokenizer and analyzer
      parameters are mutually

      exclusive. KnownTokenizerNames is an enum containing known values.

      NOTE: Either analyzerName or tokenizerName is required in an
      AnalyzeRequest.
    fullName: tokenizerName
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'tokenizerName?: string'
      return:
        description: ''
        type: string
